{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for scraping\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "from selenium import webdriver\n",
    "chromedriver = '/Applications/chromedriver'\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n",
    "# for cleaning\n",
    "import pandas as pd\n",
    "import seaborn as sbn\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "# for modeling\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_by_area_links_Seattle = [\n",
    "    'https://www.redfin.com/city/16163/WA/Seattle/filter/include=sold-5yr,viewport=47.74409:47.69068:-122.30638:-122.40011',\n",
    "    'https://www.redfin.com/city/16163/WA/Seattle/filter/include=sold-5yr,viewport=47.73611:47.68268:-122.2574:-122.35113',\n",
    "    'https://www.redfin.com/city/16163/WA/Seattle/filter/include=sold-5yr,viewport=47.70017:47.67345:-122.31544:-122.3623', \n",
    "    'https://www.redfin.com/city/16163/WA/Seattle/filter/include=sold-5yr,viewport=47.7098:47.65635:-122.34018:-122.43391', \n",
    "    'https://www.redfin.com/city/16163/WA/Seattle/filter/include=sold-5yr,viewport=47.6748:47.62132:-122.30136:-122.39509', \n",
    "    'https://www.redfin.com/city/16163/WA/Seattle/filter/include=sold-5yr,viewport=47.69562:47.64215:-122.24063:-122.33435', \n",
    "    'https://www.redfin.com/city/16163/WA/Seattle/filter/include=sold-5yr,viewport=47.63781:47.61105:-122.31995:-122.36682', \n",
    "    'https://www.redfin.com/city/16163/WA/Seattle/filter/include=sold-5yr,viewport=47.67059:47.56356:-122.21313:-122.40058', \n",
    "    'https://www.redfin.com/city/16163/WA/Seattle/filter/include=sold-5yr,viewport=47.59167:47.56489:-122.37725:-122.42411', \n",
    "    'https://www.redfin.com/city/16163/WA/Seattle/filter/include=sold-5yr,viewport=47.5792:47.52562:-122.32803:-122.42176', \n",
    "    'https://www.redfin.com/city/16163/WA/Seattle/filter/include=sold-5yr,viewport=47.54585:47.49223:-122.31099:-122.40472',\n",
    "    'https://www.redfin.com/city/16163/WA/Seattle/filter/include=sold-5yr,viewport=47.59386:47.5403:-122.26363:-122.35736', \n",
    "    'https://www.redfin.com/city/16163/WA/Seattle/filter/include=sold-5yr,viewport=47.5791:47.52552:-122.22798:-122.32171',\n",
    "    'https://www.redfin.com/city/16163/WA/Seattle/filter/include=sold-5yr,viewport=47.53334:47.47971:-122.20693:-122.30066']\n",
    "\n",
    "def scrape_sales_pages(salespages_list):\n",
    "    \"\"\"\n",
    "    Takes in a list of complete urls for sold pages within a given area; fetches relative urls for listings.\n",
    "    At the moment, Redfin will only go up to page 17 within a given geographical boundary.\n",
    "\n",
    "    salespages_list: list of complete urls (redfin.com/...) as strings\n",
    "    \"\"\"\n",
    "    sales_links = []\n",
    "    salespages_missed = []\n",
    "    salespages_completed = []\n",
    "    error_list = []\n",
    "    user_agent = UserAgent()\n",
    "    for pagelink in salespages_list:\n",
    "        for i in range(17):\n",
    "            if i > 1:\n",
    "                target_url = (pagelink + '/page-' + str(i))\n",
    "            else:\n",
    "                target_url = pagelink\n",
    "            user_agent = {'User-agent': user_agent.random}\n",
    "            try:\n",
    "                response  = requests.get(target_url, headers = user_agent)\n",
    "                time.sleep(2)\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                for pagelink in soup.find_all('a', class_ = 'slider-item hidden'):\n",
    "                    sales_links.append(pagelink.get('href'))\n",
    "            except:\n",
    "                error_list.append(sys.exc_info()[0])\n",
    "                error_list.append(response.status_code)\n",
    "                salespages_missed.append(target_url)\n",
    "            time.sleep(random.random()*11)\n",
    "        salespages_completed.append(pagelink)\n",
    "    # Geo areas overlap; dropping duplicates of urls\n",
    "    return {'listing_links': list(set(sales_links)), 'pages_scraped': salespages_completed, 'pages_missed': salespages_missed}\n",
    "\n",
    "listing_links = scrape_sales_pages(sold_by_area_links_Seattle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_listing_pages(sales_links, pickle_it = True):\n",
    "    \"\"\"\n",
    "    Given a list of relative Redfin links (/WA/Seattle...), uses selenium and chromedriver to\n",
    "    load listing pages, scroll down, and scrape page source. SLOW because of that but no catchpa \n",
    "    issues. Returns a list of scraped soup objects recast as strings at even indices and their \n",
    "    corresponding links at the subsequent odd indices.\n",
    "\n",
    "    sales_links: input list of relative links to Redfin listings as strings\n",
    "    pickle_it: should function regularly dump scrapes (True) or deliver all at end (False)\n",
    "    listingpage_scrapes: output list of alternating scrapes as strings and urls as strings\n",
    "    \"\"\"\n",
    "    base_url = 'https://www.redfin.com'\n",
    "    listingpage_scrapes = []\n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "    counter = 1\n",
    "    # Iterating through list of links\n",
    "    for link in sales_links:\n",
    "        listing_url = base_url + link\n",
    "        driver.get(listing_url)\n",
    "        for i in range(14):\n",
    "            #Scroll\n",
    "            driver.execute_script(\"window.scrollBy({top: 700,left: 0,behavior: 'smooth'});\")\n",
    "            time.sleep(0.5 + random.random()*1.5)\n",
    "        # Getting the page source and soupifying it\n",
    "        time.sleep(2)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        listingpage_scrapes.append(soup)\n",
    "        listingpage_scrapes.append(link)\n",
    "        counter += 1\n",
    "        # Intermittent pickling of raw html scrapes\n",
    "        if pickle_it & counter%100 == 0:\n",
    "            dump_list = [str(x) for x in listingpage_scrapes]\n",
    "            with open(('listingpage_scrapes_dump' + str(counter) + '.txt'), 'wb') as file_pointer:\n",
    "                pickle.dump(dump_list, file_pointer)\n",
    "    if pickle_it:\n",
    "        dump_list = [str(x) for x in listingpage_scrapes]\n",
    "        with open(('listingpage_scrapes_dump' + str(counter) + '.txt'), 'wb') as file_pointer:\n",
    "            pickle.dump(dump_list, file_pointer)\n",
    "        return (str(counter) + ' done and pickled.')\n",
    "    if not pickle_it:\n",
    "        return listingpage_scrapes\n",
    "\n",
    "# Scraping content from individual listing pages\n",
    "listing_scrapes = scrape_listing_pages(listing_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_scrapes = []\n",
    "dumps_list = ['listingpage_scrapes_dump100', 'listingpage_scrapes_dump200', \n",
    "              'listingpage_scrapes_dump300', 'listingpage_scrapes_dump400', 'listingpage_scrapes_dump500', \n",
    "              'listingpage_scrapes_dump600', 'listingpage_scrapes_dump700', 'listingpage_scrapes_dump800', \n",
    "              'listingpage_scrapes_dump900', 'listingpage_scrapes_dump1000', 'listingpage_scrapes_dump1100', \n",
    "              'listingpage_scrapes_dump1200', 'listingpage_scrapes_dump1300', 'listingpage_scrapes_dump1400', \n",
    "              'listingpage_scrapes_dump1500', 'listingpage_scrapes_dump1600', 'listingpage_scrapes_dump1700', \n",
    "              'listingpage_scrapes_dump1800', 'listingpage_scrapes_dump1900', 'listingpage_scrapes_dump2000', \n",
    "              'listingpage_scrapes_dump2100', 'listingpage_scrapes_dump2200', 'listingpage_scrapes_dump2300', \n",
    "              'listingpage_scrapes_dump2400', 'listingpage_scrapes_dump2500', 'listingpage_scrapes_dump2600', \n",
    "              'listingpage_scrapes_dump2700', 'listingpage_scrapes_dump2800', 'listingpage_scrapes_dump2900', \n",
    "              'listingpage_scrapes_dump3112']\n",
    "\n",
    "for i in dumps_list:\n",
    "    with open((i+'.txt'), 'rb') as fp:\n",
    "        listing_scrapes += pickle.load(fp)\n",
    "        \n",
    "for i in range(0, len(listing_scrapes), 2):\n",
    "    listing_scrapes[i] = BeautifulSoup(listing_scrapes[i], 'html.parser')\n",
    "\n",
    "def parse_sold_page(soup, url):\n",
    "    \"\"\"\n",
    "    Grabs desired information from Redfin page for a single sold property using BeatifulSoup.\n",
    "    Returns a dictionary of the desired information.\n",
    "    \"\"\"\n",
    "    pull_digits = re.compile('[0-9.]+')\n",
    "    property_dict = {}\n",
    "    try:\n",
    "        property_dict['address'] = soup.find('span', class_ = 'street-address').text\n",
    "    except:\n",
    "        property_dict['address'] = ''\n",
    "    try:\n",
    "        property_dict['ZIP'] = soup.find('span', class_ = 'postal-code').text\n",
    "    except:\n",
    "        property_dict['ZIP'] = ''\n",
    "    try:\n",
    "        property_dict['comm'] = soup.find(string = 'Community').find_next('span', class_ = 'content text-right').text\n",
    "    except:\n",
    "        property_dict['comm'] = ''\n",
    "    try:\n",
    "        property_dict['price'] = pull_digits.search(soup.find('div', class_ = 'info-block price').text.replace(',', '')).group()\n",
    "    except:\n",
    "        property_dict['price'] = ''\n",
    "    try:\n",
    "        property_dict['beds'] = pull_digits.search(soup.find(attrs = {'data-rf-test-id': \"abp-beds\"}).find('div', class_ = 'statsValue').text).group()\n",
    "    except:\n",
    "        property_dict['beds'] = ''\n",
    "    try:\n",
    "        property_dict['baths'] = pull_digits.search(soup.find(attrs = {'data-rf-test-id': \"abp-baths\"}).find('div', class_ = 'statsValue').text).group()\n",
    "    except:\n",
    "        property_dict['baths'] = ''\n",
    "    try:\n",
    "        property_dict['size'] = pull_digits.search(soup.find('div', class_ = 'info-block sqft').find('span', class_ = 'statsValue').text.replace(',', '')).group()\n",
    "    except:\n",
    "        property_dict['size'] = ''\n",
    "    try:\n",
    "        property_dict['style'] = soup.find(string = 'Style').find_next().text\n",
    "    except:\n",
    "        property_dict['style'] = ''\n",
    "    try:\n",
    "        property_dict['lot'] = pull_digits.search(soup.find(string = 'Lot Size').find_next().text.replace(',', '')).group()\n",
    "    except:\n",
    "        property_dict['lot'] = ''\n",
    "    try:\n",
    "        property_dict['age'] = soup.find(string = 'Year Built').find_next().text\n",
    "    except:\n",
    "        property_dict['age'] = ''\n",
    "    try:\n",
    "        property_dict['status'] = soup.find(attrs = {'data-rf-test-id': 'abp-status'}).find('span', class_ = 'value').text\n",
    "    except:\n",
    "        property_dict['status'] = ''\n",
    "    try:\n",
    "        property_dict['sold'] = soup.find('div', class_ = \"Pill Pill--red padding-vert-smallest padding-horiz-smaller font-size-smaller font-weight-bold font-color-white HomeSash margin-top-smallest margin-right-smaller\").text.replace('SOLD BY REDFIN ', '')\n",
    "    except:\n",
    "        property_dict['sold'] = ''\n",
    "    try:\n",
    "        property_dict['park'] = soup.find(string = 'Parking Information').find_next().text\n",
    "    except:\n",
    "        property_dict['park'] = ''\n",
    "    try:\n",
    "        property_dict['brok'] = pull_digits.search(soup.find(string = \"Buyer's Brokerage Compensation\").find_next('span', class_ = 'content text-right').text).group()\n",
    "    except:\n",
    "        property_dict['brok'] = ''\n",
    "    property_dict['url'] = url\n",
    "    return property_dict\n",
    "    \n",
    "data_dicts = []\n",
    "for i in range(0, len(listing_scrapes), 2):\n",
    "    data_dicts.append(parse_sold_page(listing_scrapes[i], listing_scrapes[i+1]))\n",
    "\n",
    "listings_data = pd.DataFrame(data_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not considering the houseboats, plexes, co-ops, and other oddballs (different enough to probably skew model)\n",
    "type_dict = {'': '',\n",
    " '1 1/2 Story': 'house',\n",
    " '1 1/2 Story with Basement': 'house',\n",
    " '1 1/2 Story with Basement, Cape Cod': 'house',\n",
    " '1 1/2 Story with Basement, Colonial': 'house',\n",
    " '1 1/2 Story with Basement, Contemporary': 'house',\n",
    " '1 1/2 Story with Basement, Craftsman': 'house',\n",
    " '1 1/2 Story with Basement, Modern': 'house',\n",
    " '1 1/2 Story with Basement, Northwestern Contemporary': 'house',\n",
    " '1 1/2 Story with Basement, Traditional': 'house',\n",
    " '1 1/2 Story with Basement, Tudor': 'house',\n",
    " '1 1/2 Story, Cape Cod': 'house',\n",
    " '1 1/2 Story, Contemporary': 'house',\n",
    " '1 1/2 Story, Craftsman': 'house',\n",
    " '1 1/2 Story, Northwestern Contemporary': 'house',\n",
    " '1 1/2 Story, Other (See Remarks)': 'house',\n",
    " '1 1/2 Story, Traditional': 'house',\n",
    " '1 1/2 Story, Tudor': 'house',\n",
    " '1 Story': 'house',\n",
    " '1 Story with Basement': 'house',\n",
    " '1 Story with Basement, Cape Cod': 'house',\n",
    " '1 Story with Basement, Contemporary': 'house',\n",
    " '1 Story with Basement, Craftsman': 'house',\n",
    " '1 Story with Basement, Modern': 'house',\n",
    " '1 Story with Basement, Northwestern Contemporary': 'house',\n",
    " '1 Story with Basement, Other (See Remarks)': 'house',\n",
    " '1 Story with Basement, Spanish/Southwestern': 'house',\n",
    " '1 Story with Basement, Traditional': 'house',\n",
    " '1 Story with Basement, Tudor': 'house',\n",
    " '1 Story, Cabin': 'house',\n",
    " '1 Story, Cape Cod': 'house',\n",
    " '1 Story, Contemporary': 'house',\n",
    " '1 Story, Craftsman': 'house',\n",
    " '1 Story, Modern': 'house',\n",
    " '1 Story, Northwestern Contemporary': 'house',\n",
    " '1 Story, Other (See Remarks)': 'house',\n",
    " '1 Story, Traditional': 'house',\n",
    " '2 Stories with Basement': 'house',\n",
    " '2 Stories with Basement, Cape Cod': 'house',\n",
    " '2 Stories with Basement, Colonial': 'house',\n",
    " '2 Stories with Basement, Contemporary': 'house',\n",
    " '2 Stories with Basement, Craftsman': 'house',\n",
    " '2 Stories with Basement, Modern': 'house',\n",
    " '2 Stories with Basement, Northwestern Contemporary': 'house',\n",
    " '2 Stories with Basement, Other (See Remarks)': 'house',\n",
    " '2 Stories with Basement, Traditional': 'house',\n",
    " '2 Stories with Basement, Tudor': 'house',\n",
    " '2 Stories with Basement, Victorian': 'house',\n",
    " '2 Story': 'house',\n",
    " '2 Story, Cape Cod': 'house',\n",
    " '2 Story, Contemporary': 'house',\n",
    " '2 Story, Craftsman': 'house',\n",
    " '2 Story, Modern': 'house',\n",
    " '2 Story, Northwestern Contemporary': 'house',\n",
    " '2 Story, Other (See Remarks)': 'house',\n",
    " '2 Story, Spanish/Southwestern': 'house',\n",
    " '2 Story, Traditional': 'house',\n",
    " '4-Plex': '',\n",
    " '5-9 Units': '',\n",
    " 'Co-op': '',\n",
    " 'Condominium (2 Levels)': 'condo',\n",
    " 'Condominium (2 Levels), Contemporary': 'condo',\n",
    " 'Condominium (2 Levels), Loft': 'condo',\n",
    " 'Condominium (2 Levels), Modern': 'condo',\n",
    " 'Condominium (2 Levels), Townhouse': 'condo',\n",
    " 'Condominium (2 Levels), Traditional': 'condo',\n",
    " 'Condominium (3+ Levels)': 'condo',\n",
    " 'Condominium (3+ Levels), Contemporary': 'condo',\n",
    " 'Condominium (3+ Levels), Modern': 'condo',\n",
    " 'Condominium (3+ Levels), Townhouse': 'condo',\n",
    " 'Condominium (Single Level)': 'condo',\n",
    " 'Condominium (Single Level), Contemporary': 'condo',\n",
    " 'Condominium (Single Level), Craftsman': 'condo',\n",
    " 'Condominium (Single Level), Loft': 'condo',\n",
    " 'Condominium (Single Level), Modern': 'condo',\n",
    " 'Condominium (Single Level), Other (See Remarks)': 'condo',\n",
    " 'Condominium (Single Level), Spanish/Southwestern': 'condo',\n",
    " 'Condominium (Single Level), Studio': 'condo',\n",
    " 'Condominium (Single Level), Traditional': 'condo',\n",
    " 'Condominium (Single Level), Tudor': 'condo',\n",
    " 'Duplex': '',\n",
    " 'Houseboat, Cabin': '',\n",
    " 'Houseboat, Contemporary': '',\n",
    " 'Manufactured Double-Wide': '',\n",
    " 'Multi-Family': '',\n",
    " 'Multi-Level': 'house',\n",
    " 'Multi-Level, Contemporary': 'house',\n",
    " 'Multi-Level, Craftsman': 'house',\n",
    " 'Multi-Level, Modern': 'house',\n",
    " 'Multi-Level, Northwestern Contemporary': 'house',\n",
    " 'Multi-Level, Other (See Remarks)': 'house',\n",
    " 'Multi-Level, Traditional': 'house',\n",
    " 'Multi-Level, Tudor': 'house',\n",
    " 'Multi-Level, Victorian': 'house',\n",
    " 'Residential (1+ Acre)': 'house',\n",
    " 'Residential (<1 Acre)': 'house',\n",
    " 'Single Family Residential': 'house',\n",
    " 'Split-Entry': 'house',\n",
    " 'Split-Entry, Contemporary': 'house',\n",
    " 'Split-Entry, Craftsman': 'house',\n",
    " 'Split-Entry, Modern': 'house',\n",
    " 'Split-Entry, Northwestern Contemporary': 'house',\n",
    " 'Split-Entry, Other (See Remarks)': 'house',\n",
    " 'Split-Entry, Traditional': 'house',\n",
    " 'Townhouse': 'townhouse',\n",
    " 'Townhouse, Contemporary': 'townhouse',\n",
    " 'Townhouse, Craftsman': 'townhouse',\n",
    " 'Townhouse, Modern': 'townhouse',\n",
    " 'Townhouse, Northwestern Contemporary': 'townhouse',\n",
    " 'Townhouse, Townhouse': 'townhouse',\n",
    " 'Townhouse, Traditional': 'townhouse',\n",
    " 'Tri-Level': 'house',\n",
    " 'Tri-Level, Cape Cod': 'house',\n",
    " 'Tri-Level, Contemporary': 'house',\n",
    " 'Tri-Level, Craftsman': 'house',\n",
    " 'Tri-Level, Modern': 'house',\n",
    " 'Tri-Level, Northwestern Contemporary': 'house',\n",
    " 'Tri-Level, Other (See Remarks)': 'house',\n",
    " 'Tri-Level, Traditional': 'house',\n",
    " 'Triplex': ''}\n",
    "basement_dict = {'': 0,\n",
    " '1 1/2 Story': 0,\n",
    " '1 1/2 Story with Basement': 1,\n",
    " '1 1/2 Story with Basement, Cape Cod': 1,\n",
    " '1 1/2 Story with Basement, Colonial': 1,\n",
    " '1 1/2 Story with Basement, Contemporary': 1,\n",
    " '1 1/2 Story with Basement, Craftsman': 1,\n",
    " '1 1/2 Story with Basement, Modern': 1,\n",
    " '1 1/2 Story with Basement, Northwestern Contemporary': 1,\n",
    " '1 1/2 Story with Basement, Traditional': 1,\n",
    " '1 1/2 Story with Basement, Tudor': 1,\n",
    " '1 1/2 Story, Cape Cod': 0,\n",
    " '1 1/2 Story, Contemporary': 0,\n",
    " '1 1/2 Story, Craftsman': 0,\n",
    " '1 1/2 Story, Northwestern Contemporary': 0,\n",
    " '1 1/2 Story, Other (See Remarks)': 0,\n",
    " '1 1/2 Story, Traditional': 0,\n",
    " '1 1/2 Story, Tudor': 0,\n",
    " '1 Story': 0,\n",
    " '1 Story with Basement': 1,\n",
    " '1 Story with Basement, Cape Cod': 1,\n",
    " '1 Story with Basement, Contemporary': 1,\n",
    " '1 Story with Basement, Craftsman': 1,\n",
    " '1 Story with Basement, Modern': 1,\n",
    " '1 Story with Basement, Northwestern Contemporary': 1,\n",
    " '1 Story with Basement, Other (See Remarks)': 1,\n",
    " '1 Story with Basement, Spanish/Southwestern': 1,\n",
    " '1 Story with Basement, Traditional': 1,\n",
    " '1 Story with Basement, Tudor': 1,\n",
    " '1 Story, Cabin': 0,\n",
    " '1 Story, Cape Cod': 0,\n",
    " '1 Story, Contemporary': 0,\n",
    " '1 Story, Craftsman': 0,\n",
    " '1 Story, Modern': 0,\n",
    " '1 Story, Northwestern Contemporary': 0,\n",
    " '1 Story, Other (See Remarks)': 0,\n",
    " '1 Story, Traditional': 0,\n",
    " '2 Stories with Basement': 1,\n",
    " '2 Stories with Basement, Cape Cod': 1,\n",
    " '2 Stories with Basement, Colonial': 1,\n",
    " '2 Stories with Basement, Contemporary': 1,\n",
    " '2 Stories with Basement, Craftsman': 1,\n",
    " '2 Stories with Basement, Modern': 1,\n",
    " '2 Stories with Basement, Northwestern Contemporary': 1,\n",
    " '2 Stories with Basement, Other (See Remarks)': 1,\n",
    " '2 Stories with Basement, Traditional': 1,\n",
    " '2 Stories with Basement, Tudor': 1,\n",
    " '2 Stories with Basement, Victorian': 1,\n",
    " '2 Story': 0,\n",
    " '2 Story, Cape Cod': 0,\n",
    " '2 Story, Contemporary': 0,\n",
    " '2 Story, Craftsman': 0,\n",
    " '2 Story, Modern': 0,\n",
    " '2 Story, Northwestern Contemporary': 0,\n",
    " '2 Story, Other (See Remarks)': 0,\n",
    " '2 Story, Spanish/Southwestern': 0,\n",
    " '2 Story, Traditional': 0,\n",
    " '4-Plex': 0,\n",
    " '5-9 Units': 0,\n",
    " 'Co-op': 0,\n",
    " 'Condominium (2 Levels)': 0,\n",
    " 'Condominium (2 Levels), Contemporary': 0,\n",
    " 'Condominium (2 Levels), Loft': 0,\n",
    " 'Condominium (2 Levels), Modern': 0,\n",
    " 'Condominium (2 Levels), Townhouse': 0,\n",
    " 'Condominium (2 Levels), Traditional': 0,\n",
    " 'Condominium (3+ Levels)': 0,\n",
    " 'Condominium (3+ Levels), Contemporary': 0,\n",
    " 'Condominium (3+ Levels), Modern': 0,\n",
    " 'Condominium (3+ Levels), Townhouse': 0,\n",
    " 'Condominium (Single Level)': 0,\n",
    " 'Condominium (Single Level), Contemporary': 0,\n",
    " 'Condominium (Single Level), Craftsman': 0,\n",
    " 'Condominium (Single Level), Loft': 0,\n",
    " 'Condominium (Single Level), Modern': 0,\n",
    " 'Condominium (Single Level), Other (See Remarks)': 0,\n",
    " 'Condominium (Single Level), Spanish/Southwestern': 0,\n",
    " 'Condominium (Single Level), Studio': 0,\n",
    " 'Condominium (Single Level), Traditional': 0,\n",
    " 'Condominium (Single Level), Tudor': 0,\n",
    " 'Duplex': 0,\n",
    " 'Houseboat, Cabin': 0,\n",
    " 'Houseboat, Contemporary': 0,\n",
    " 'Manufactured Double-Wide': 0,\n",
    " 'Multi-Family': 0,\n",
    " 'Multi-Level': 0,\n",
    " 'Multi-Level, Contemporary': 0,\n",
    " 'Multi-Level, Craftsman': 0,\n",
    " 'Multi-Level, Modern': 0,\n",
    " 'Multi-Level, Northwestern Contemporary': 0,\n",
    " 'Multi-Level, Other (See Remarks)': 0,\n",
    " 'Multi-Level, Traditional': 0,\n",
    " 'Multi-Level, Tudor': 0,\n",
    " 'Multi-Level, Victorian': 0,\n",
    " 'Residential (1+ Acre)': 0,\n",
    " 'Residential (<1 Acre)': 0,\n",
    " 'Single Family Residential': 0,\n",
    " 'Split-Entry': 0,\n",
    " 'Split-Entry, Contemporary': 0,\n",
    " 'Split-Entry, Craftsman': 0,\n",
    " 'Split-Entry, Modern': 0,\n",
    " 'Split-Entry, Northwestern Contemporary': 0,\n",
    " 'Split-Entry, Other (See Remarks)': 0,\n",
    " 'Split-Entry, Traditional': 0,\n",
    " 'Townhouse': 0,\n",
    " 'Townhouse, Contemporary': 0,\n",
    " 'Townhouse, Craftsman': 0,\n",
    " 'Townhouse, Modern': 0,\n",
    " 'Townhouse, Northwestern Contemporary': 0,\n",
    " 'Townhouse, Townhouse': 0,\n",
    " 'Townhouse, Traditional': 0,\n",
    " 'Tri-Level': 0,\n",
    " 'Tri-Level, Cape Cod': 0,\n",
    " 'Tri-Level, Contemporary': 0,\n",
    " 'Tri-Level, Craftsman': 0,\n",
    " 'Tri-Level, Modern': 0,\n",
    " 'Tri-Level, Northwestern Contemporary': 0,\n",
    " 'Tri-Level, Other (See Remarks)': 0,\n",
    " 'Tri-Level, Traditional': 0,\n",
    " 'Triplex': 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: dicts are only comprehensize for dataset scraped; check dataframe after mapping\n",
    "listings_data['type'] = listings_data['style'].map(type_dict)\n",
    "listings_data['basement'] = listings_data['style'].map(basement_dict)\n",
    "converted_data = listings_data\n",
    "converted_data['price'] = pd.to_numeric(converted_data['price'], 'coerce')\n",
    "converted_data['beds'] = pd.to_numeric(converted_data['beds'], 'coerce')\n",
    "converted_data['baths'] = pd.to_numeric(converted_data['baths'], 'coerce')\n",
    "converted_data['lot'] = pd.to_numeric(converted_data['lot'], 'coerce')\n",
    "converted_data['brok'] = pd.to_numeric(converted_data['brok'], 'coerce')\n",
    "converted_data['age'] = pd.to_datetime(converted_data['age'], 'coerce')\n",
    "converted_data['sold'] = pd.to_datetime(converted_data['sold'], 'coerce')\n",
    "converted_data['size'] = pd.to_numeric(converted_data['size'], 'coerce')\n",
    "# Dropping information not used/needed for model; all listings in this set were status == 'sold'\n",
    "converted_data.drop(columns = ['address', 'comm', 'style', 'status', 'url', 'park'], inplace = True)\n",
    "# Mask out plexes, houseboats, etc.\n",
    "blank_type_mask = (converted_data['type'] != '')\n",
    "# Mask out missing values for critical values\n",
    "critical_vals_mask = converted_data['price'].notnull() & converted_data['beds'].notnull() & converted_data['baths'].notnull() & converted_data['size'].notnull()\n",
    "converted_data = converted_data[blank_type_mask & critical_vals_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age is really when built; need to get a years from then to now for actual age\n",
    "def calc_house_age(build_date):\n",
    "    return dt.datetime.today().year - build_date.year\n",
    "converted_data['age'] = converted_data['age'].apply(calc_house_age)\n",
    "\n",
    "# Replace null brok with mode (is by FAR the most common value)\n",
    "converted_data['brok'] = converted_data['brok'].fillna(3.0, inplace = True)\n",
    "\n",
    "# Deal with tiny-lot houses (actually in acres) and null-lot townhouses/condos (actually 0)\n",
    "converted_data.loc[((converted_data.type == 'house') & (converted_data.lot < 1)), 'lot'] = converted_data['lot']*43560\n",
    "converted_data.loc[((converted_data['type'] == 'townhouse') | (converted_data['type'] == 'condo')) & converted_data['lot'].isnull(), 'lot'] = 0\n",
    "\n",
    "# Moving ZIP to quintiles of mean ppsqft (approx. equal # listings)\n",
    "zip_quintiles = {98101: 5, 98121: 5, 98164: 5, 98102: 5, 98109: 5, 98122: 5, 98119: 5, \n",
    "                 98107: 4, 98155: 4, 98112: 4, 98104: 4, 98103: 4, 98105: 4, \n",
    "                 98115: 3, 98144: 3, 98116: 3, 98177: 3, 98199: 3, \n",
    "                 98117: 2, 98136: 2, 98126: 2, 98133: 2, 98125: 2, \n",
    "                 98108: 1, 98166: 1, 98118: 1, 98106: 1, 98134: 1, 98146: 1, 98188: 1, 98178: 1, 98168: 1}\n",
    "converted_data_simple['ZIP'] = converted_data_simple['ZIP'].map(zip_quintiles)\n",
    "\n",
    "# Age of sale in years\n",
    "def sale_age_conversion(datetime):\n",
    "    return (dt.datetime.today() - datetime).days/365\n",
    "converted_data_simple['sale_age'] = converted_data_simple['sold'].map(sale_age_conversion)\n",
    "converted_data_simple.drop(columns = ['sold'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_plot = sbn.pairplot(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = converted_data_simple\n",
    "model_data = pd.get_dummies(converted_data_simple, prefix = 't', columns = ['type'], drop_first = True)\n",
    "sbn.heatmap(model_data.corr(), cmap=\"seismic\", annot=True, vmin=-1, vmax=1)\n",
    "plt.gca().set_ylim(len(model_data.corr())+0.5, -0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_plot = sbn.pairplot(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One $6M house was fine in terms of size and price but was throwing off a lot of other interactions\n",
    "mansion_mask = model_data['price'] < 4000000\n",
    "model_data = model_data[mansion_mask]\n",
    "model_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "X = model_data[['ZIP', 'beds', 'baths', 'size', 'lot', 'age', 'sold', 'basement', 't_house', 't_townhouse']]\n",
    "y = model_data['price']\n",
    "# Splitting data into test/validate (60-20%) and holdout (20%); random states generated by random.org\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2,random_state=11)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.25, random_state=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pf = PolynomialFeatures()\n",
    "X_train_poly = pf.fit_transform(X_train)\n",
    "\n",
    "linreg_poly = LinearRegression()\n",
    "linreg_poly.fit(X_train_poly, y_train)\n",
    "print(linreg_poly.score(X_train_poly, y_train))\n",
    "print(linred_poly.score(X_val_poly, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(pf.get_feature_names(X_train.columns), linreg_poly.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfit somewhat; removing features using LASSO to see if I can improve performance\n",
    "std = StandardScaler()\n",
    "std.fit(X_train.values)\n",
    "X_train_sc = std.transform(X_train.values)\n",
    "X_val_sc = std.transform(X_val.values)\n",
    "X_train_polysc = pf.fit_transform(X_train_sc)\n",
    "X_val_polysc = pf.fit_transform(X_val_sc)\n",
    "\n",
    "# Finding an alpha to minimize total error\n",
    "alphalist = 10**(np.linspace(-2,2,200))\n",
    "err_vec_val = np.zeros(len(alphalist))\n",
    "err_vec_train = np.zeros(len(alphalist))\n",
    "\n",
    "#Mean Absolute Error (MAE)\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_pred - y_true)) \n",
    "\n",
    "for i,curr_alpha in enumerate(alphalist):\n",
    "    lasso = Lasso(alpha = curr_alpha)\n",
    "    lasso.fit(X_train_polysc, y_train)\n",
    "    val_set_pred = lasso.predict(X_val_polysc)\n",
    "    err_vec_val[i] = mae(y_val, val_set_pred)\n",
    "\n",
    "plt.plot(np.log10(alphalist), err_vec_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding an alpha to minimize total error\n",
    "alphalist = 10**(np.linspace(2,4,200))\n",
    "err_vec_val = np.zeros(len(alphalist))\n",
    "err_vec_train = np.zeros(len(alphalist))\n",
    "min_error = 100000\n",
    "best_alpha = 0\n",
    "\n",
    "for i,curr_alpha in enumerate(alphalist):\n",
    "    lasso = Lasso(alpha = curr_alpha)\n",
    "    lasso.fit(X_train_polysc, y_train)\n",
    "    val_set_pred = lasso.predict(X_val_polysc)\n",
    "    this_mae = mae(y_val, val_set_pred)\n",
    "    if min_error > this_mae:\n",
    "        min_error = this_mae\n",
    "        best_alpha = curr_alpha\n",
    "    err_vec_val[i] = this_mae\n",
    "\n",
    "plt.plot(np.log10(alphalist), err_vec_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_opt = Lasso(alpha = best_alpha)\n",
    "lasso_opt.fit(X_train_polysc, y_train)\n",
    "lasso_coef_tuples = list(zip(pf.get_feature_names(X_train.columns), lasso_opt.coef_))\n",
    "lasso_coef_tuples = sorted(lasso_coef_tuples, key = lambda x: abs(x[1]))\n",
    "lasso_coef_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have reasons to believe that all the basic features are going to be useful for price prediction.\n",
    "\n",
    "Basic features LASSO zeroed out:\n",
    "- beds\n",
    "- basement\n",
    "- t_townhouse\n",
    "\n",
    "Features to maybe add:\n",
    "- size * ZIP\n",
    "- size * t_townhouse\n",
    "- sold^2\n",
    "\n",
    "Features to possibly add and see if it helps:\n",
    "- baths*size\n",
    "- baths*lot\n",
    "- size*sold\n",
    "- beds^2\n",
    "- age^2\n",
    "\n",
    "1. Will add features back to various datasets (X_test, X_val, X_test)\n",
    "2. Run linear regression using a list of features of only the basics; get MAE\n",
    "3. Run linear regression using a list of only the basics plus six*ZIP; get MAE\n",
    "4. Rinse repeat until it seems like the marginal benefit of additional features is small-to-nonexistent or until I reach the end of the lists here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPolyFeatures(df):\n",
    "    df.loc[:, 'sizeZIP'] = df.loc[:, 'size'] * df.loc[:, 'ZIP']\n",
    "    df.loc[:, 'sizeiftown'] = df.loc[:, 'size'] * df.loc[:, 't_townhouse']\n",
    "    df.loc[:, 'sold^2'] = df.loc[:, 'sold']**2\n",
    "    df.loc[:, 'bathssize'] = df.loc[:, 'baths'] * df.loc[:, 'size']\n",
    "    df.loc[:, 'bathslot'] = df.loc[:, 'baths'] * df.loc[:, 'lot']\n",
    "    df.loc[:, 'sizesold'] = df.loc[:, 'size'] * df.loc[:, 'sold']\n",
    "    df.loc[:, 'beds^2'] = df.loc[:, 'beds']**2\n",
    "    df.loc[:, 'age^2'] = df.loc[:, 'age']**2\n",
    "    return df\n",
    "\n",
    "X_train = addPolyFeatures(X_train)\n",
    "X_val = addPolyFeatures(X_val)\n",
    "X_test = addPolyFeatures(X_test)\n",
    "\n",
    "features_list = ['ZIP', 'beds', 'baths', 'size', 'lot', 'age', 'sold', 'basement', \n",
    "                 't_house', 't_townhouse', 'sizeZIP', 'sizeiftown', 'sold^2', \n",
    "                 'bathssize', 'bathslot', 'sizesold', 'beds^2', 'age^2']\n",
    "model = sm.OLS(y_train, X_train[features_list[0:10]])\n",
    "fit = model.fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(fit.predict(), fit.resid)\n",
    "plt.axhline(0, linestyle='--', color='gray')\n",
    "plt.xlabel('Predicted price', fontsize=18)\n",
    "plt.ylabel('Residuals', fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsme(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_pred - y_true)**2))\n",
    "print(mae(y_train, fit.predict()))\n",
    "print(rsme(y_train, fit.predict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_list = []\n",
    "rsme_list = []\n",
    "for i in range(10, 19):\n",
    "    model = sm.OLS(y_train, sm.add_constant(X_train[features_list[0:i]]))\n",
    "    fit = model.fit()\n",
    "    prediction = fit.predict(sm.add_constant(X_val[features_list[0:i]]))\n",
    "    mae_list.append(mae(y_val, prediction))\n",
    "    rsme_list.append(rsme(y_val, prediction))\n",
    "\n",
    "plt.plot(range(10, 19), mae_list, color = 'red')\n",
    "plt.plot(range(10, 19), rsme_list, color = 'blue')\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('House price error ($)')\n",
    "plt.title('Error reduction as polynomial features added')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did try subtracting the feature that didn't help; worse results. Discussed with Brian who pointed out that this approach is sensitive to the order of feature addition. LASSO again to see if I can reduce the complexity while preserving sensibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc = std.transform(X_train.values)\n",
    "X_val_sc = std.transform(X_val.values)\n",
    "# Finding an alpha to minimize total error\n",
    "alphalist = 10**(np.linspace(-2,2,200))\n",
    "err_vec_val = np.zeros(len(alphalist))\n",
    "err_vec_train = np.zeros(len(alphalist))\n",
    "min_error = 100000\n",
    "best_alpha = 0\n",
    "\n",
    "for i,curr_alpha in enumerate(alphalist):\n",
    "    lasso = Lasso(alpha = curr_alpha)\n",
    "    lasso.fit(X_train_sc, y_train)\n",
    "    val_set_pred = lasso.predict(X_val_sc)\n",
    "    this_mae = mae(y_val, val_set_pred)\n",
    "    if min_error > this_mae:\n",
    "        min_error = this_mae\n",
    "        best_alpha = curr_alpha\n",
    "    err_vec_val[i] = this_mae\n",
    "\n",
    "plt.plot(np.log10(alphalist), err_vec_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(best_alpha)\n",
    "lasso.fit(X_train_sc, y_train)\n",
    "lasso_coef_tuples = list(zip(X_train.columns, lasso_opt.coef_))\n",
    "lasso_coef_tuples = sorted(lasso_coef_tuples, key = lambda x: abs(x[1]))\n",
    "lasso_coef_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list3 = ['lot', 'beds', 'bathslot', 'size', 'basement', 't_townhouse', 'sold', 'beds^2', 'age^2', 'sizesold', 'age']\n",
    "model = sm.OLS(y_train, X_train[features_list3])\n",
    "fit = model.fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(fit.predict(), fit.resid)\n",
    "plt.axhline(0, linestyle='--', color='gray')\n",
    "plt.xlabel('Predicted price', fontsize=18)\n",
    "plt.ylabel('Residuals', fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mae(y_train, fit.predict()))\n",
    "print(rsme(y_train, fit.predict()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling can't capture the intangibles\n",
    "This model is rather worse than the more complicated model. Fundamentally, I didn't capture some of the features that are likely contributing substantially to the final sold price of a home (view, newness of interior, curb appeal, etc.). \n",
    "\n",
    "Instead of trying to figure out how much a house should be listed for, let's instead try to capture how much different first order features contribute to a house's sale price. Step one will be running LASSO on X_train2 (unchewed data set) to see if there are any features that should be tossed out and see if we agree with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting this going again without overwriting model or train/val sets I want to use again.\n",
    "X_train_val2, X_test2, y_train_val2, y_test2 = train_test_split(X, y, test_size=0.2,random_state=93)\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(X_train_val2, y_train_val2, test_size=.25, random_state=98)\n",
    "std = StandardScaler()\n",
    "std.fit(X_train2)\n",
    "X_train2_sc = std.transform(X_train2.values)\n",
    "X_val2_sc = std.transform(X_val2.values)\n",
    "\n",
    "# Finding an alpha to minimize total error\n",
    "alphalist = 10**(np.linspace(-2,2,200))\n",
    "err_vec_val = np.zeros(len(alphalist))\n",
    "err_vec_train = np.zeros(len(alphalist))\n",
    "min_error = 100000\n",
    "best_alpha = 0\n",
    "\n",
    "for i,curr_alpha in enumerate(alphalist):\n",
    "    lasso = Lasso(alpha = curr_alpha)\n",
    "    lasso.fit(X_train2_sc, y_train2)\n",
    "    val_set_pred = lasso.predict(X_val2_sc)\n",
    "    this_mae = mae(y_val2, val_set_pred)\n",
    "    if min_error > this_mae:\n",
    "        min_error = this_mae\n",
    "        best_alpha = curr_alpha\n",
    "    err_vec_val[i] = this_mae\n",
    "\n",
    "plt.plot(np.log10(alphalist), err_vec_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding an alpha to minimize total error\n",
    "alphalist = 10**(np.linspace(2,4,200))\n",
    "err_vec_val = np.zeros(len(alphalist))\n",
    "err_vec_train = np.zeros(len(alphalist))\n",
    "min_error = 100000\n",
    "best_alpha = 0\n",
    "\n",
    "for i,curr_alpha in enumerate(alphalist):\n",
    "    lasso = Lasso(alpha = curr_alpha)\n",
    "    lasso.fit(X_train2_sc, y_train2)\n",
    "    val_set_pred = lasso.predict(X_val2_sc)\n",
    "    this_mae = mae(y_val2, val_set_pred)\n",
    "    if min_error > this_mae:\n",
    "        min_error = this_mae\n",
    "        best_alpha = curr_alpha\n",
    "    err_vec_val[i] = this_mae\n",
    "\n",
    "plt.plot(np.log10(alphalist), err_vec_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(best_alpha)\n",
    "lasso.fit(X_train2_sc, y_train2)\n",
    "lasso_coef_tuples = list(zip(X_train2.columns, lasso_opt.coef_))\n",
    "lasso_coef_tuples = sorted(lasso_coef_tuples, key = lambda x: abs(x[1]))\n",
    "lasso_coef_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting! Basements are actually a minus (finished basement sqft worth less than main floor sqft, mayhaps?). Sold date works exactly as I'd expect, a discount for times in the past to account for inflation and increases in house prices.\n",
    "\n",
    "Definitely surprised that location and number of baths don't matter! I wonder how much of that is homogeneity in \"niceness/richness\" of neighborhood within a given ZIP and how much is just that relatively little variation is accounted for by ZIP alone (i.e. houses in nicer areas also tend to be larger). That said, I think that it's important for my purposes to keep bath in; ZIP can go. We'll see what house type does after that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression on final features list using train/val 80% chunk\n",
    "features_list4 = ['beds', 'baths', 'size', 'age', 'sold', 'lot', 'basement', 't_house', 't_townhouse']\n",
    "model = sm.OLS(y_train_val2, X_train_val2[features_list4])\n",
    "fit = model.fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very much leaning on https://zhiyzuo.github.io/Python-Plot-Regression-Coefficient/ to graph coefficients w/ CI\n",
    "error_bars = fit.params - fit.conf_int()[0]\n",
    "coef_df = pd.DataFrame({'coefficient': fit.params.values,\n",
    "                       'error': error_bars.values,\n",
    "                       'variable': error_bars.index.values})\n",
    "fig, ax = plt.subplots()\n",
    "coef_df.plot(x = 'variable', y = 'coefficient', kind = 'bar', ax = ax, yerr = 'error')\n",
    "ax.set_xlabel('')\n",
    "ax.axhline(y=0, linestyle='--', color='black', linewidth=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
